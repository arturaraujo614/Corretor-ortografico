{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"artigos.txt\", \"r\",encoding = 'utf-8') as f:\n",
    "    artigos = f.read()\n",
    "\n",
    "print(artigos[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Uso do Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spli separa a frase por default, espaço\n",
    "texto_exemplo = \"Olá, tudo bem?\"\n",
    "tokens = texto_exemplo.split()\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_tokenize vai separar as palavras de uma frase e pontuações\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "palavras_separadas = nltk.tokenize.word_tokenize(texto_exemplo)\n",
    "print(palavras_separadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'palavras'.isalpha()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separa_palavras(lista_tokens):\n",
    "    lista_palavras = []\n",
    "    for token in lista_tokens:\n",
    "        if token.isalpha():\n",
    "            lista_palavras.append(token)\n",
    "    return lista_palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "separa_palavras(palavras_separadas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lista de Palavras - Excluindo caracteres sem ser alfanumérico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_tokens = nltk.tokenize.word_tokenize(artigos)\n",
    "lista_palavras = separa_palavras(lista_tokens)\n",
    "print(f\"O número de palavras é: {len(lista_palavras)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tornando todas as palavras com letras minusculas\n",
    "##### Isso serve para que na proxima etapa, o algoritmo consiga excluir palavras repetidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizacao(lista_palavras):\n",
    "    lista_normalizadas = []\n",
    "    for palavra in lista_palavras:\n",
    "        lista_normalizadas.append(palavra.lower())\n",
    "    return lista_normalizadas\n",
    "\n",
    "lista_normalizadas = normalizacao(lista_palavras)\n",
    "print(lista_normalizadas[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Excluir palavras repetidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set exclui as palavras repetidas\n",
    "len(set(lista_normalizadas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corrigindo palavras com ausência de alguma letra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A função abaixo irá receber a tupla gerada na def gerador_palavras\n",
    "def insere_letras(fatias):\n",
    "    novas_palavras = []\n",
    "    letras = 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç'\n",
    "    for E,D in fatias:\n",
    "        for letra in letras:\n",
    "            novas_palavras.append(E + letra + D)\n",
    "    return novas_palavras\n",
    "#Pelo duplo 'for', a função irá operar todas as letras em 'letras' para depois ir para a segunda tupla (fatias)\n",
    "# A def insere_letras retorna uma lista com todas as combinações possíveis de concatenação E+letra+D\n",
    "\n",
    "#A def gerador_palavras recebe a palavra/lista que deve separar em esquerda e direita\n",
    "palavra_exemplo=\"lgica\"\n",
    "def gerador_palavras(palavra):\n",
    "    fatias = []\n",
    "    for i in range(len(palavra)+1):\n",
    "        fatias.append((palavra[:i],palavra[i:]))\n",
    "\n",
    "    palavras_geradas = insere_letras(fatias)\n",
    "    return palavras_geradas\n",
    "#insere_palavras(fatias) já está chamando a função principal.\n",
    "# A def gerador_palavras entrega a tupla com a(s) palavra(s) fatiada(s)\n",
    "\n",
    "palavras_geradas = gerador_palavras(palavra_exemplo)\n",
    "print(palavras_geradas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corretor(palavra):\n",
    "    palavras_geradas = gerador_palavras(palavra)\n",
    "    #max retorna o elemento de max a partir de uma função chave. No caso, a função usada é a probabilidade\n",
    "    palavra_correta = max(palavras_geradas,key=probabilidade)\n",
    "    return palavra_correta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencia = nltk.FreqDist(lista_normalizadas)\n",
    "total_palavra = len(lista_normalizadas)\n",
    "#frequencia.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probabilidade(palavras_geradas):\n",
    "    return frequencia[palavras_geradas]/total_palavra\n",
    "probabilidade('lógica')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corretor(palavra_exemplo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testando a Eficiência do Corretor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cria_dados_teste(nome_arquivo):\n",
    "    lista_palavras_teste = []\n",
    "    f = open(nome_arquivo,\"r\",encoding = 'utf-8')\n",
    "    for linha in f:\n",
    "        correta,errada = linha.split()\n",
    "        lista_palavras_teste.append((correta,errada))\n",
    "    f.close()\n",
    "    return lista_palavras_teste\n",
    "\n",
    "lista_teste = cria_dados_teste(\"palavras.txt\")\n",
    "lista_teste\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avaliador(testes):\n",
    "    numero_de_palavras = len(testes)\n",
    "    acertou = 0\n",
    "    for correta, errada in testes:\n",
    "        palavra_corrigida = corretor(errada)\n",
    "        if palavra_corrigida == correta:\n",
    "            acertou +=1\n",
    "    taxa_acerto = round(acertou*100/numero_de_palavras,2)\n",
    "    print(f'taxa de acerto foi de {taxa_acerto}% no total de {numero_de_palavras} palavras')\n",
    "\n",
    "avaliador(lista_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corrigindo palavras com adição de algum caractere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deletando_caractere(fatias):\n",
    "    novas_palavras = []\n",
    "    letras = 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç'\n",
    "    for E,D in fatias:\n",
    "        novas_palavras.append(E + D[1:])\n",
    "    return novas_palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerador_palavras(palavra):\n",
    "    fatias = []\n",
    "    for i in range(len(palavra)+1):\n",
    "        fatias.append((palavra[:i],palavra[i:]))\n",
    "\n",
    "    palavras_geradas = insere_letras(fatias)\n",
    "    palavras_geradas +=deletando_caractere(fatias)\n",
    "    return palavras_geradas\n",
    "\n",
    "palavra_exemplo = \"lóigica\"\n",
    "palavras_geradas = gerador_palavras(palavra_exemplo)\n",
    "print(palavras_geradas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avaliador(lista_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corrigindo palavras com troca de letras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insere_letras(fatias):\n",
    "    novas_palavras = []\n",
    "    letras = 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç'\n",
    "    for E,D in fatias:\n",
    "        for letra in letras:\n",
    "            novas_palavras.append(E + letra + D)\n",
    "    return novas_palavras\n",
    "\n",
    "def deletando_caractere(fatias):\n",
    "    novas_palavras = []\n",
    "    letras = 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç'\n",
    "    for E,D in fatias:\n",
    "        novas_palavras.append(E + D[1:])\n",
    "    return novas_palavras\n",
    "\n",
    "def troca_letra(fatias):\n",
    "    novas_palavras = []\n",
    "    letras = 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç'\n",
    "    for E,D in fatias:\n",
    "        for letra in letras:\n",
    "            novas_palavras.append(E + letra + D[1:])\n",
    "    return novas_palavras\n",
    "\n",
    "def inverte_caractere(fatias):\n",
    "    novas_palavras = []\n",
    "    for E,D in fatias:\n",
    "        if len(D) > 1:\n",
    "            novas_palavras.append(E + D[1] + D[0] + D[2:])\n",
    "    return novas_palavras\n",
    "\n",
    "def gerador_palavras(palavra):\n",
    "    fatias = []\n",
    "    for i in range(len(palavra)+1):\n",
    "        fatias.append((palavra[:i],palavra[i:]))\n",
    "\n",
    "    palavras_geradas = insere_letras(fatias)\n",
    "    palavras_geradas += deletando_caractere(fatias)\n",
    "    palavras_geradas += troca_letra(fatias)\n",
    "    palavras_geradas += inverte_caractere(fatias)\n",
    "    return palavras_geradas\n",
    "\n",
    "palavra_exemplo = \"lgóica\"\n",
    "palavras_geradas = gerador_palavras(palavra_exemplo)\n",
    "print(palavras_geradas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avaliador(lista_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avaliador(testes,vocabulario):\n",
    "    numero_de_palavras = len(testes)\n",
    "    desconhecida = 0\n",
    "    acertou = 0\n",
    "    for correta, errada in testes:\n",
    "        palavra_corrigida = corretor(errada)\n",
    "        if palavra_corrigida == correta:\n",
    "            acertou +=1\n",
    "        else:\n",
    "            desconhecida += (correta not in vocabulario)\n",
    "    taxa_acerto = round(acertou*100/numero_de_palavras,2)\n",
    "    taxa_desconhecida = round(desconhecida*100/numero_de_palavras,2)\n",
    "    print(f'taxa de acerto foi de {taxa_acerto}% no total de {numero_de_palavras} palavras, desconhecida é {taxa_desconhecida}')\n",
    "\n",
    "vocabulario = set(lista_normalizadas)\n",
    "avaliador(lista_teste,vocabulario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palavra = \"lóiigca\"\n",
    "def gerador_turbinado(palavras_geradas):\n",
    "    novas_palavras = []\n",
    "    for palavra in palavras_geradas:\n",
    "        novas_palavras += gerador_palavras(palavra)\n",
    "    return novas_palavras\n",
    "\n",
    "palavras_g = gerador_turbinado(gerador_palavras(palavra))\n",
    "\"lógica\" in palavras_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "550534"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(palavras_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'lógica'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def novo_corretor(palavra):\n",
    "    palavras_geradas = gerador_palavras(palavra)\n",
    "    palavras_turbinadas = gerador_turbinado(palavras_geradas)\n",
    "    todas_palavras = set(palavras_geradas+palavras_turbinadas)\n",
    "    candidatos = [palavra]\n",
    "    for palavra in todas_palavras:\n",
    "        if palavra in vocabulario:\n",
    "            candidatos.append(palavra)\n",
    "    print(len(candidatos))\n",
    "    palavra_correta = max(candidatos,key=probabilidade)\n",
    "    return palavra_correta\n",
    "\n",
    "novo_corretor(palavra)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5f1b78eb436411a9c3c2406ff65dd6a2a483e2b78ec2ae8c1343ef3e593983b6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
